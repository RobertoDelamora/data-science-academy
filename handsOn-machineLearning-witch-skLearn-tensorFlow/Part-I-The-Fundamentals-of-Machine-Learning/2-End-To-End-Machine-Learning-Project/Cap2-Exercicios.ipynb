{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Preparação-dos-Dados\" data-toc-modified-id=\"Preparação-dos-Dados-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Preparação dos Dados</a></span><ul class=\"toc-item\"><li><span><a href=\"#8.1---SVM\" data-toc-modified-id=\"8.1---SVM-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>8.1 - SVM</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparação dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando módulos necessários - Tratamento dos Dados\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tarfile\n",
    "from six.moves import urllib\n",
    "\n",
    "# Importando módulos necessários - Preparação de Dados\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import Imputer\n",
    "from future_encoders import OneHotEncoder\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from future_encoders import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Importando módulos necessários - Treinamento\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Importando módulos necessários - Métricas e Validações\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Importando módulos necessários - Sintonizando e Salvando o Modelo\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scipy.stats import geom, expon\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após a importação dos módulos, a primeira coisa a se fazer é ler o arquivo e **separar** o conjunto em datasets de treino e de teste. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download realizado com sucesso! Arquivo pode ser encontrado em: \n",
      "datasets\\housing/housing.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>ocean_proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-122.23</td>\n",
       "      <td>37.88</td>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-122.22</td>\n",
       "      <td>37.86</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-122.24</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>352100.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>341300.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>342200.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0    -122.23     37.88                41.0        880.0           129.0   \n",
       "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
       "2    -122.24     37.85                52.0       1467.0           190.0   \n",
       "3    -122.25     37.85                52.0       1274.0           235.0   \n",
       "4    -122.25     37.85                52.0       1627.0           280.0   \n",
       "\n",
       "   population  households  median_income  median_house_value ocean_proximity  \n",
       "0       322.0       126.0         8.3252            452600.0        NEAR BAY  \n",
       "1      2401.0      1138.0         8.3014            358500.0        NEAR BAY  \n",
       "2       496.0       177.0         7.2574            352100.0        NEAR BAY  \n",
       "3       558.0       219.0         5.6431            341300.0        NEAR BAY  \n",
       "4       565.0       259.0         3.8462            342200.0        NEAR BAY  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definindo variáveis e função para extração do dataset\n",
    "DOWNLOAD_ROOT = 'https://raw.githubusercontent.com/ageron/handson-ml/master/' # Define url root onde encontram-se os arquivos\n",
    "HOUSING_PATH = os.path.join('datasets', 'housing') # Pasta onde será(ão) organizado(s) o(s) arquivo(s)\n",
    "HOUSING_URL = DOWNLOAD_ROOT + 'datasets/housing/housing.csv' # Parte específica da url para baixar arquivo específico\n",
    "\n",
    "def fetch_housing_data(housing_url=HOUSING_URL, housing_path=HOUSING_PATH):\n",
    "    \"\"\"\n",
    "    Dada uma URL, esta função é responsável por realizar o download, extração e organização de datasets automaticamente\n",
    "    \n",
    "    INPUTS: \n",
    "    housing_url = URL no qual se encontra o arquivo a ser baixado.\n",
    "    housing_path = caminho dentro do SO onde o arquivo será armazenado.\n",
    "    \"\"\"\n",
    "    if not os.path.isdir(housing_path): # Se não há pasta com o nome específicado, cria uma no SO.\n",
    "        os.makedirs(housing_path) \n",
    "    if 'tgz' in housing_url: # Se trata-se de um arquivo .tgz (Linux)\n",
    "        try: \n",
    "            filename = 'housing'\n",
    "            extension = '.tgz'\n",
    "            tgz_path = os.path.join(housing_path, filename+extension)\n",
    "            urllib.request.urlretrieve(housing_url, tgz_path)\n",
    "            housing_tgz = tarfile.open(tgz_path)\n",
    "            housing_tgz.extractall(path=housing_path)\n",
    "            housing_tgz.close\n",
    "        except tarfile.ReadError:\n",
    "            print('Erro de Leitura: Não foi possível abrir o arquivo.')\n",
    "        except urllib.error.URLError:\n",
    "            print('Erro HTTP: URL não encontrada (Erro 404).')\n",
    "    elif 'csv' in housing_url: # Se trata-se de um arquivo .csv\n",
    "        try:\n",
    "            filename = 'housing' # Nome do arquivo\n",
    "            extension = '.csv' # Extensão\n",
    "            csv_path = os.path.join(housing_path, filename+extension) # Mapeando caminho no SO\n",
    "            urllib.request.urlretrieve(housing_url, csv_path) # Acessa link para download\n",
    "        except urllib.error.URLError:\n",
    "            print('Erro HTTP: URL não encontrada (Erro 404).')\n",
    "        else:\n",
    "            print(f'Download realizado com sucesso! Arquivo pode ser encontrado em: \\n{housing_path+\"/\"+filename+extension}')\n",
    "\n",
    "# Chamando função\n",
    "fetch_housing_data()\n",
    "\n",
    "# Função para leitura de arquivo\n",
    "def load_housing_data(housing_path=HOUSING_PATH):\n",
    "    csv_path = os.path.join(housing_path, 'housing.csv')\n",
    "    return pd.read_csv(csv_path)\n",
    "\n",
    "# Lendo arquivo\n",
    "housing = load_housing_data()\n",
    "\n",
    "# Verificando cabeçalho\n",
    "housing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape do dataset original: (20640, 11)\n",
      "Shape de strat_train_set: (16512, 11)\n",
      "Shape de strat_test_set: (4128, 11)\n",
      "Shape de housing modificado: (16512, 9)\n",
      "Shape de housing_labels: (16512,)\n"
     ]
    }
   ],
   "source": [
    "# Criando nova categoria\n",
    "housing['income_cat'] = np.ceil(housing['median_income'] / 1.5) # Limitando valores\n",
    "housing['income_cat'].where(housing['income_cat'] < 5, 5.0, inplace=True)\n",
    "\n",
    "# Separando dataset\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=.2, random_state=42)\n",
    "for train_index, test_index in split.split(housing, housing['income_cat']):\n",
    "    strat_train_set = housing.loc[train_index]\n",
    "    strat_test_set = housing.loc[test_index]\n",
    "\n",
    "# Comparando\n",
    "print(f'Shape do dataset original: {housing.shape}')\n",
    "print(f'Shape de strat_train_set: {strat_train_set.shape}')\n",
    "print(f'Shape de strat_test_set: {strat_test_set.shape}')\n",
    "\n",
    "# Excluindo colunas adicionais\n",
    "for set_ in (strat_train_set, strat_test_set):\n",
    "    set_.drop('income_cat', axis=1, inplace=True)\n",
    "    \n",
    "# Criando cópia\n",
    "housing = strat_train_set.drop('median_house_value', axis=1)\n",
    "housing_labels = strat_train_set['median_house_value'].copy()\n",
    "\n",
    "print(f'Shape de housing modificado: {housing.shape}')\n",
    "print(f'Shape de housing_labels: {housing_labels.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classe responsável por combinar alguns atributos do dataset\n",
    "\n",
    "rooms_ix, bedrooms_ix, population_ix, household_ix = 3, 4, 5, 6\n",
    "\n",
    "class CombinadorAtributos(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Classe criada para combinar atributos e criar novas features de acordo com as informações contidas no Dataset.\n",
    "    Atributos criados:\n",
    "        - \n",
    "    \"\"\"\n",
    "    def __init__(self, add_bedrooms_per_room=True, add_rooms_per_population=True):\n",
    "        \"\"\"\n",
    "        Método construtor: define hiperparâmetros, neste caso, combinações entre atributos diferentes\n",
    "            - add_bedrooms_per_room\n",
    "            - add_rooms_per_population\n",
    "        \"\"\"\n",
    "        self.add_bedrooms_per_room = add_bedrooms_per_room\n",
    "        self.add_rooms_per_population = add_rooms_per_population\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        rooms_per_household = X[:, rooms_ix] / X[:, household_ix]\n",
    "        population_per_household = X[:, population_ix] / X[:, household_ix]\n",
    "        if self.add_bedrooms_per_room:\n",
    "            bedrooms_per_room = X[:, bedrooms_ix] / X[:, rooms_ix]\n",
    "            if self.add_rooms_per_population:\n",
    "                rooms_per_population = X[:, rooms_ix] / X[:, population_ix]\n",
    "                return np.c_[X, rooms_per_household, population_per_household, bedrooms_per_room,\n",
    "                            rooms_per_population]\n",
    "            else:\n",
    "                return np.c_[X, rooms_per_household, population_per_household, bedrooms_per_room]\n",
    "        if self.add_rooms_per_population:\n",
    "            rooms_per_population = X[:, rooms_ix] / X[:, population_ix]\n",
    "            return np.c_[X, rooms_per_household, population_per_household, rooms_per_population]\n",
    "        else:\n",
    "            return np.c_[X, rooms_per_household, population_per_household]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5> **APLICANDO PIPELINE** </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape housing original: (16512, 9)\n",
      "Shape housing_prepared: (16512, 17)\n"
     ]
    }
   ],
   "source": [
    "# Definições iniciais \n",
    "num_attribs = list(housing.drop('ocean_proximity', axis=1))\n",
    "cat_attribs = ['ocean_proximity']\n",
    "\n",
    "# Definindo Pipeline numérico\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer', Imputer(strategy=\"median\")),\n",
    "    ('attribs_adder', CombinadorAtributos()),\n",
    "    ('std_scaler', StandardScaler()),\n",
    "])\n",
    "\n",
    "# Executando todo o Pipeline\n",
    "full_pipeline = ColumnTransformer([\n",
    "    ('num', num_pipeline, num_attribs),\n",
    "    ('cat', OneHotEncoder(sparse=False), cat_attribs)\n",
    "])\n",
    "\n",
    "# Definindo dados preparados\n",
    "housing_prepared = full_pipeline.fit_transform(housing)\n",
    "\n",
    "# Comparando\n",
    "print(f'Shape housing original: {housing.shape}')\n",
    "print(f'Shape housing_prepared: {housing_prepared.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1 - SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try a Support Vector Machine regressor (```sklearn.svm.SVR```) wth various hyperparameters such as ```kernel=linear``` (with various values for the C hyperparameter) or ```kernel=\"rbf\"``` (with various values for the C and ```gamma``` hyperparameters). How does the best SVR predictor perform?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando algorítimo SVM\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([179160.75917566, 179940.53375474, 179191.67464573, ...,\n",
       "       179299.85241107, 179594.29436694, 179564.67686674])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Treinando algorítimo sem nenhuma especificação\n",
    "svm_reg = SVR()\n",
    "svm_reg.fit(housing_prepared, housing_labels)\n",
    "svm_reg.predict(housing_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118573.30094001174"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Realizando predições com a totalidade do conjunto de treinamento\n",
    "housing_predictions = svm_reg.predict(housing_prepared)\n",
    "\n",
    "# Calculando o erro RMSE (sem raíz quadrada)\n",
    "svm_mse = mean_squared_error(housing_labels, housing_predictions)\n",
    "\n",
    "# Aplicando raíz quadrada\n",
    "svm_rmse = np.sqrt(svm_mse)\n",
    "svm_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando com os demais algorítimos em um pipeline\n",
    "def model_train(df_prepared, df_labels, \n",
    "                lin_reg=False, svm_reg=False, tree_reg=False, forest_reg=False):\n",
    "    \"\"\"\n",
    "    Função que recebe dados de entrada e um algorítimo selecionado para realizar o treinamento completo\n",
    "    \"\"\"\n",
    "    # Verificando o modelo escolhido\n",
    "    if lin_reg:\n",
    "        model = LinearRegression()\n",
    "        desc = 'Linear Regression'\n",
    "    elif svm_reg:\n",
    "        model = SVR()\n",
    "        desc = 'SVM'\n",
    "    elif tree_reg:\n",
    "        model = DecisionTreeRegressor()\n",
    "        desc = 'Decision Tree Regressor'\n",
    "    elif forest_reg:\n",
    "        model = RandomForestRegressor()\n",
    "        desc = 'Random Forest Regressor'\n",
    "    else:\n",
    "        print('Nenhum modelo selecionado.')\n",
    "        return\n",
    "    \n",
    "    # Treinando e computando erro\n",
    "    model.fit(df_prepared, df_labels)\n",
    "    model_predictions = model.predict(df_prepared)\n",
    "    model_mse = mean_squared_error(df_labels, model_predictions)\n",
    "    model_rmse = np.sqrt(model_mse)\n",
    "    print(f'Erro Médio Quadrádico para {desc}: {model_rmse:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erro Médio Quadrádico para Linear Regression: 67324.65\n",
      "Erro Médio Quadrádico para SVM: 118573.30\n",
      "Erro Médio Quadrádico para Decision Tree Regressor: 0.00\n",
      "Erro Médio Quadrádico para Random Forest Regressor: 22174.99\n"
     ]
    }
   ],
   "source": [
    "model_train(housing_prepared, housing_labels, lin_reg=True)\n",
    "model_train(housing_prepared, housing_labels, svm_reg=True)\n",
    "model_train(housing_prepared, housing_labels, tree_reg=True)\n",
    "model_train(housing_prepared, housing_labels, forest_reg=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
